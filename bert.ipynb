{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79cad23-89a5-4993-96cb-b9970056b628",
   "metadata": {},
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e16ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import torch \n",
    "from scipy.sparse import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pyarrow as pa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import DistilBertConfig,DistilBertTokenizer,DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5253c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292c4374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "7                     0                       0      5  1336003200   \n",
       "8                     1                       1      5  1322006400   \n",
       "9                     0                       0      5  1351209600   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                          Good Quality Dog Food   \n",
       "1                              Not as Advertised   \n",
       "2                          \"Delight\" says it all   \n",
       "3                                 Cough Medicine   \n",
       "4                                    Great taffy   \n",
       "5                                     Nice Taffy   \n",
       "6  Great!  Just as good as the expensive brands!   \n",
       "7                         Wonderful, tasty taffy   \n",
       "8                                     Yay Barley   \n",
       "9                               Healthy Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  \n",
       "5  I got a wild hair for taffy and ordered this f...  \n",
       "6  This saltwater taffy had great flavors and was...  \n",
       "7  This taffy is so good.  It is very soft and ch...  \n",
       "8  Right now I'm mostly just sprouting this so my...  \n",
       "9  This is a very healthy dog food. Good for thei...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/amazon-product-reviews/Reviews.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8599d663-401f-4e05-bbb2-df5bd9ea9f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not as Advertised'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cd95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['Text']\n",
    "scores = df['Score'] # rating between 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38b45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = texts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b77f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"gelu\",\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"transformers_version\": \"4.6.0\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DistilBertConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2155c87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ac596d6b8f4064b085627636f956e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7a4d76eb5d4edbbfcbf782310694ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff32ff5eee65460b83c30a3c88e0d3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef29c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    \n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "          x,\n",
    "          add_special_tokens=True,\n",
    "          max_length=max_seq_length,\n",
    "          return_token_type_ids=False,\n",
    "          pad_to_max_length=True,\n",
    "          #padding=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "          truncation=True\n",
    "        )\n",
    "    return encoding['input_ids'].flatten(), encoding['attention_mask'].flatten()\n",
    "    \n",
    "    '''\n",
    "    #tokenized_comment = tokenizer.tokenize(x)\n",
    "    if len(tokenized_comment) > max_seq_length:\n",
    "        tokenized_comment = tokenized_comment[:max_seq_length]\n",
    "\n",
    "    ids_review  = tokenizer.convert_tokens_to_ids(tokenized_comment)\n",
    "\n",
    "    padding = [0] * (max_seq_length - len(ids_review))\n",
    "\n",
    "    ids_review += padding\n",
    "\n",
    "    assert len(ids_review) == max_seq_length\n",
    "\n",
    "    #print(ids_review)\n",
    "    ids_review = torch.tensor(ids_review)\n",
    "\n",
    "    #hcc = self.y[index] # toxic comment        \n",
    "    #list_of_labels = [torch.from_numpy(hcc)]\n",
    "    #return ids_review, list_of_labels[0]\n",
    "    return ids_review\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3217e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f7daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertSequence(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        #self.num_labels = config.num_labels\n",
    "\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        #self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        #self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        #self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "        #nn.init.xavier_normal_(self.classifier.weight)\n",
    "    \n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None): #,head_mask=None,labels=None):\n",
    "        distilbert_output = self.distilbert(input_ids=input_ids,\n",
    "                                            attention_mask=attention_mask)\n",
    "        hidden_state = distilbert_output[0]                    \n",
    "        pooled_output = hidden_state[:, 0]  \n",
    "        return pooled_output\n",
    "        #pooled_output = self.pre_classifier(pooled_output)   \n",
    "        #pooled_output = nn.ReLU()(pooled_output)             \n",
    "        #pooled_output = self.dropout(pooled_output)        \n",
    "        #logits = self.classifier(pooled_output) \n",
    "        #return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ed24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/.cache/pypoetry/virtualenvs/dd2424-text-summarization-GSmT3uUC-py3.8/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a417f99c295b4f78889fe6126ade1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bafdd27c7ab4f6e84eaf58eeaacb373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5643e-02, -3.5159e-02,  1.5530e-02, -2.3242e-01,  2.2430e-02,\n",
      "         -7.0673e-02,  1.9809e-01,  3.2892e-01, -6.6505e-02, -1.9768e-01,\n",
      "          1.2504e-01,  1.3313e-01,  1.4475e-01,  1.1562e-01, -3.0118e-01,\n",
      "          1.3435e-01,  3.3235e-02,  5.0848e-01,  1.9977e-01,  1.1225e-01,\n",
      "          8.9052e-02, -6.2093e-01,  1.2021e-01,  3.3409e-01,  5.6048e-02,\n",
      "          1.2262e-01,  2.0878e-01,  1.4484e-01,  2.3509e-01, -1.4653e-01,\n",
      "          3.7198e-01,  1.2625e-01, -1.4292e-01, -2.4212e-01,  2.0895e-01,\n",
      "         -1.8431e-02,  1.6187e-01, -2.4050e-01, -2.8422e-01,  5.2403e-02,\n",
      "         -1.2108e-01,  2.8366e-01,  6.1746e-02,  1.5687e-01, -9.4009e-02,\n",
      "         -1.7512e-01, -3.0254e+00, -1.1415e-01,  1.1723e-01, -1.5747e-01,\n",
      "          1.9896e-01, -1.5239e-01,  1.0354e-02,  2.8528e-01,  4.2127e-01,\n",
      "          5.2762e-01, -6.2068e-01,  2.3257e-01, -2.4997e-01, -5.2612e-02,\n",
      "          1.0061e-01,  1.5803e-01, -3.2713e-02,  1.8643e-01, -1.3009e-01,\n",
      "          3.0736e-01, -1.2108e-01,  4.2376e-02, -1.9307e-01,  5.8087e-01,\n",
      "         -4.1893e-02, -1.9814e-01,  2.5596e-02, -1.7330e-03,  3.3186e-02,\n",
      "          5.7560e-02, -4.4320e-02, -1.2740e-03,  4.8604e-02,  3.7101e-01,\n",
      "          2.7061e-01,  3.1923e-01,  1.8314e-01,  1.0635e-01,  1.9186e-01,\n",
      "          2.1002e-01, -9.8345e-02, -6.8133e-02,  7.9142e-02,  3.3490e-01,\n",
      "         -2.7951e-01, -1.9768e-02,  9.0326e-02,  1.8908e-01,  4.7029e-01,\n",
      "         -3.3998e-01,  1.5141e-01, -2.7231e-01,  1.9094e-01,  2.1512e-01,\n",
      "          8.7281e-02, -3.9228e-02,  3.1717e-02, -3.1976e-01,  1.8647e-03,\n",
      "         -2.5729e-01, -1.0216e-01, -4.4315e-01, -1.0788e-02, -1.9041e+00,\n",
      "          3.2614e-01,  9.4112e-02, -1.2476e-02, -3.5106e-01, -1.6733e-01,\n",
      "          1.8045e-01,  1.1479e-01,  8.0149e-02, -6.2847e-02,  2.7927e-02,\n",
      "          8.7202e-02,  1.1959e-01, -2.8347e-01, -3.3009e-01, -2.0159e-01,\n",
      "          1.3449e-01, -3.0347e-01,  3.2670e-03,  1.5326e-01,  1.4707e-01,\n",
      "          3.6828e-01,  3.8820e-01,  5.1931e-02, -2.0806e-01, -1.6310e-01,\n",
      "          4.4483e-01,  1.7631e-01, -1.6648e-01, -3.9381e-02,  2.4011e-02,\n",
      "         -1.1582e-01, -1.3084e-01, -2.4737e+00,  2.1203e-01,  3.7601e-01,\n",
      "          9.3741e-02,  8.2001e-02,  1.3112e-01, -9.6615e-02,  9.7054e-02,\n",
      "          2.3372e-01,  1.0773e-01, -2.9820e-01, -1.6414e-01, -8.7396e-02,\n",
      "         -1.4105e-01, -3.4669e-01, -2.7143e-02,  2.2015e-01,  1.3164e-01,\n",
      "          2.5952e-01, -2.5708e-01, -4.6830e-02, -1.0505e-01, -8.9703e-02,\n",
      "          2.2059e-01,  3.8436e-01,  8.6051e-02, -1.9011e-01,  9.0778e-02,\n",
      "         -5.3347e-02,  3.4899e-01,  5.9064e-01, -3.3824e-01,  1.8910e-01,\n",
      "         -5.8037e-02, -7.3817e-02,  2.4703e-01,  2.1527e-01, -2.1468e-01,\n",
      "         -1.1897e-01,  4.1971e-01,  1.8107e-01,  8.1637e-02,  2.9578e-01,\n",
      "         -1.8858e-01,  1.6913e-01, -3.4998e-01, -2.2232e-01,  1.1346e-01,\n",
      "         -2.7177e-01, -5.8435e-01,  1.1372e-03, -2.0810e-02,  2.9264e-01,\n",
      "          1.5574e-01,  1.2059e-01, -3.7415e-01,  2.5460e-03, -3.2709e-02,\n",
      "         -3.2528e-01, -6.8658e-02, -3.6693e-02,  1.5264e-02, -1.3939e-01,\n",
      "          3.2069e+00,  1.3371e-01, -1.2045e-01,  3.0653e-01,  4.1216e-01,\n",
      "         -1.2981e-01,  8.4929e-02, -1.3048e-01,  7.2760e-02, -1.6825e-01,\n",
      "         -2.4620e-02,  2.8468e-01,  1.0186e-01,  2.7763e-02,  1.9129e-02,\n",
      "          7.6569e-02,  2.4989e-01, -5.2875e-01,  3.3893e-01, -7.2040e-02,\n",
      "         -7.2141e-02, -1.5765e-01,  2.1692e-01,  2.3936e-01, -1.1842e+00,\n",
      "          1.7430e-01, -1.9699e-01, -5.2758e-02,  2.3917e-01, -4.2209e-01,\n",
      "          2.7788e-02,  1.8929e-01,  7.2354e-02,  3.0115e-01, -1.0033e-01,\n",
      "         -1.7905e-01,  5.6186e-01,  6.6357e-02,  2.3590e-01, -2.9658e-01,\n",
      "          4.4665e-01,  5.0450e-02,  1.5873e-01, -1.3211e-01, -3.9141e-01,\n",
      "          4.8456e-01,  4.5217e-02,  2.2829e-01, -1.3732e-01,  4.2283e-01,\n",
      "         -4.2781e-03, -2.5748e-02,  2.8593e-01, -2.4399e-01, -1.0192e-01,\n",
      "         -2.5384e-01,  7.3559e-02, -7.0969e-02,  2.3714e-01, -4.3776e-01,\n",
      "         -2.6496e-01, -1.8233e-01, -4.1190e-01,  9.6931e-02,  1.1340e-01,\n",
      "         -7.0024e-02, -6.1415e-02, -4.5932e-01, -2.5781e+00,  2.8829e-02,\n",
      "         -2.7897e-01,  4.1346e-02,  1.7846e-01,  1.1898e-01, -4.2850e-02,\n",
      "          2.4364e-01,  2.5686e-01, -3.3040e-01,  3.3970e-01, -7.4020e-02,\n",
      "         -2.5723e-02,  1.9853e-01, -7.0140e-01,  1.4747e-01,  3.0628e-02,\n",
      "         -1.6996e-01,  1.2856e-01, -4.8191e-01, -1.4280e-01,  5.8382e-02,\n",
      "          2.6613e-02,  2.5435e-01,  2.0662e-01,  2.8129e-01, -4.0052e-01,\n",
      "         -9.5081e-02, -9.7374e-02,  2.7691e-01,  1.7684e-01, -2.3408e-01,\n",
      "          1.3066e-01, -4.3543e-01, -4.6111e-01, -3.7063e+00,  1.1070e-01,\n",
      "         -1.2609e-01, -2.0490e-01,  2.1376e-01, -1.4232e-01,  3.8665e-01,\n",
      "         -1.0380e-01, -3.3367e-01,  4.1934e-01,  3.2606e-01,  1.0338e-01,\n",
      "          1.6760e-01, -4.0121e-03,  2.7024e-01, -3.3817e-02,  3.8121e-01,\n",
      "         -3.4341e-01,  3.8959e-01,  4.2459e-01,  3.1408e-01, -1.0326e-01,\n",
      "         -1.5071e-01,  3.2645e-03,  3.5259e-01,  3.5197e-01, -4.5022e-01,\n",
      "         -1.9782e-01, -9.1841e-02, -2.1481e-01,  1.2082e-02, -3.7430e-01,\n",
      "         -2.5075e-02, -2.7413e-01, -5.0842e-02, -1.4452e-01, -2.5294e-01,\n",
      "          9.4884e-03,  3.6586e-01, -1.0703e-01,  1.8033e-01,  7.0905e-01,\n",
      "          4.1651e-01,  4.4917e-02,  5.4584e-01,  1.8552e-01,  5.3057e-02,\n",
      "         -2.6232e-01,  2.9087e-02,  3.1007e-01,  1.7514e-01,  1.2969e-01,\n",
      "          1.0295e+00,  7.2063e-02,  8.8257e-02, -4.9861e-01,  4.3768e-01,\n",
      "         -7.5157e-02, -1.5475e-01,  2.3437e-01,  2.7451e-01, -4.5672e-01,\n",
      "          7.7832e-02, -3.5210e-01,  1.2990e-02, -3.0810e-02,  1.3066e-01,\n",
      "         -5.3035e-01, -1.5485e-01, -5.0955e-03,  9.7181e-03, -2.2744e-02,\n",
      "         -1.4727e-01, -9.3816e-01, -1.0769e-01, -2.1570e-01,  3.3532e-02,\n",
      "         -9.7453e-02, -1.5004e-01,  8.8090e-02, -1.3798e-01, -2.9975e-01,\n",
      "         -1.5233e-02,  2.5356e-01, -3.2371e-01, -4.2490e-01, -2.5150e-01,\n",
      "          1.2031e-01, -5.2369e-01, -1.8367e-01,  8.5659e-02,  1.5616e-03,\n",
      "         -1.3400e-02,  1.3336e-01,  8.7429e-03, -3.8941e-02,  2.5148e-01,\n",
      "         -7.7334e-01,  2.4662e-01, -3.1624e-01,  1.4781e-01, -1.0272e-01,\n",
      "         -9.1763e-04, -7.9017e-04, -1.4998e-02, -4.2469e-01,  3.7421e-02,\n",
      "          3.4246e-01,  4.4679e-01,  4.8966e-02, -3.0876e-01, -8.5611e-02,\n",
      "          5.7513e-02, -7.4945e-02,  8.3978e-01,  1.3587e-01,  2.0431e-01,\n",
      "          4.7141e-02,  8.0467e-04,  1.3435e-01,  5.0370e-01, -1.2769e-01,\n",
      "         -1.8643e-01, -3.9403e-02, -1.9428e-01, -2.2889e-01,  1.8097e-01,\n",
      "         -2.6032e-01, -4.7868e-01,  5.2375e-02,  1.4250e-01, -9.7827e-03,\n",
      "         -4.3983e-01, -4.1015e-01, -4.4959e-02, -8.7805e-02, -2.1314e-01,\n",
      "         -1.5933e-02,  1.0906e-01, -1.0961e-01,  2.5769e-01,  3.6229e-01,\n",
      "         -2.6406e-01,  4.1717e-01, -2.9695e-01,  4.1549e-01,  1.1269e-01,\n",
      "          1.4594e-02, -1.2672e-02,  1.5134e-01,  8.6790e-03,  7.5640e-02,\n",
      "         -1.2315e-01, -2.7627e-01,  5.0033e-01,  1.6199e-01,  2.5236e-01,\n",
      "          2.6831e-01, -6.2306e-02,  2.6544e-02,  1.3952e-01,  1.0856e-02,\n",
      "         -1.6150e+00,  2.9816e-01,  9.5912e-02,  3.1469e-01,  8.4395e-03,\n",
      "         -3.3329e-01, -1.9318e-01,  6.0406e-01,  1.7917e-01,  5.9396e-02,\n",
      "         -7.9172e-02, -1.1364e-02,  7.5077e-02,  5.6070e-02, -1.5831e-02,\n",
      "         -8.8525e-03, -1.8587e-01,  1.0675e-01, -1.3797e-01, -1.9681e-01,\n",
      "         -1.0561e-02,  2.2360e-01,  6.4482e-02,  2.6124e-01,  5.0756e-02,\n",
      "         -3.4836e-01,  1.8837e-01,  1.5195e-01,  1.7283e-01,  4.3188e-01,\n",
      "         -2.2718e-01, -1.6229e-01, -7.8846e-01, -1.1780e-01,  2.0040e-01,\n",
      "         -2.6905e-02,  6.3494e-02, -2.0015e-01,  2.9924e-01,  4.0216e-01,\n",
      "         -5.5880e-01,  4.3198e-01,  3.0103e-01,  4.3811e-02,  3.4578e-01,\n",
      "          1.0206e-01, -1.1270e-01,  2.2690e-01, -7.1660e-02, -2.1854e-01,\n",
      "          2.8916e-01, -1.5330e-02, -2.6686e-01,  1.2615e-01,  2.1976e-02,\n",
      "         -8.2163e-03, -5.1660e-02,  2.2509e-01, -3.5193e-01, -2.9420e-01,\n",
      "          1.8658e-01, -2.6220e-01, -4.0598e-01,  1.1340e-01, -3.4332e-01,\n",
      "         -6.5976e-01, -1.6182e-01, -2.7443e-01, -7.6952e-02,  3.2520e-02,\n",
      "          5.5934e-01, -1.3392e-01, -2.6555e-01,  2.3740e-01, -1.2831e-01,\n",
      "          2.8311e-01,  1.6059e-01,  2.7039e-01,  4.2985e-01,  2.3905e-01,\n",
      "          8.8166e-02, -8.5040e-02, -2.8913e-01,  1.9347e-01, -1.7895e-01,\n",
      "          2.3246e-01, -2.7958e-01, -2.0329e-01,  2.3608e-01,  2.1720e-01,\n",
      "         -7.9171e-02,  1.5960e-01,  5.1310e-03, -2.0222e-01, -7.3104e-02,\n",
      "          1.0093e-01, -8.5267e-02, -1.2774e-01, -7.2110e-02,  1.3675e-02,\n",
      "         -2.2704e-01,  4.4982e-01,  4.9278e-01,  2.3794e-01, -3.1769e-01,\n",
      "         -8.6689e-02,  5.2846e-02,  6.6241e-03, -3.3878e-01, -6.4951e-03,\n",
      "          5.1416e-01, -4.6915e-02,  1.5543e-01,  1.1353e-01,  3.3686e-04,\n",
      "         -4.0153e-01,  6.9418e-02, -4.4952e-01,  1.9348e+00,  4.1059e-01,\n",
      "          1.5436e-01, -2.1951e-02,  9.4525e-03, -5.2728e-02, -2.8574e-01,\n",
      "          1.8425e-01, -1.5520e-01,  4.8996e-01, -3.8358e-02,  2.8231e-01,\n",
      "         -1.3461e-01,  3.2558e-02,  5.0862e-01,  1.0747e-01,  2.3491e-01,\n",
      "         -1.9156e-01, -5.5729e-01, -4.4736e-02, -4.8840e-01,  2.5796e-01,\n",
      "          2.0467e-01, -1.1634e-01, -1.1192e-03,  1.9502e-01,  3.1784e-01,\n",
      "          1.4570e-01,  2.0138e-01,  3.7135e-01, -6.7837e-02, -2.7536e-02,\n",
      "          2.3762e-01,  1.8360e-01, -1.9061e-01, -7.1671e-02, -4.4596e-02,\n",
      "         -2.9951e-01, -2.6879e-02,  2.0832e-01,  1.7136e-01, -5.2304e-01,\n",
      "          1.5419e-01,  1.5908e-01, -9.2349e-02,  5.3201e-01, -2.0340e-01,\n",
      "         -5.1274e-02,  3.1538e-01,  2.1932e-01, -3.5987e-01,  9.5884e-02,\n",
      "         -1.2547e-01,  2.4848e-01, -1.8232e-01,  2.9844e-02, -2.4511e-01,\n",
      "         -8.4499e-02, -2.7228e-01,  2.5207e-01, -2.3706e-01,  1.7229e-01,\n",
      "          1.1605e-01, -4.2797e-02,  1.7953e-01,  2.0413e-01, -2.5382e-01,\n",
      "         -5.0355e-02,  4.5726e-01, -3.1546e-01, -3.1731e-02,  4.0481e-01,\n",
      "          3.8506e-01,  1.2273e-01,  1.2095e-01,  1.3278e-01,  4.0387e-01,\n",
      "         -1.8725e-01, -1.7779e-01, -1.7807e+00,  6.1837e-02, -1.8535e-01,\n",
      "          1.0011e-01,  3.6272e-02,  3.1517e-01,  2.0224e-01, -7.4440e-02,\n",
      "         -2.7369e-01,  6.6884e-03,  4.4740e-01,  2.1356e-01,  4.1996e-01,\n",
      "         -9.2391e-03,  7.4574e-02, -1.2173e-01,  2.1138e-01, -3.1599e-01,\n",
      "         -2.5884e-01, -4.4659e-02,  2.6897e-01,  6.2458e-02,  2.1004e-01,\n",
      "         -2.0103e-01, -5.3930e-01,  9.4669e-02,  2.3940e-02, -2.5894e-01,\n",
      "         -1.2590e-01,  1.0076e-01, -4.7848e-02,  5.3426e-01, -3.2031e-01,\n",
      "         -3.2352e-01, -6.3617e-02, -2.0747e-03, -3.5315e-01,  9.6572e-02,\n",
      "         -7.7276e-02,  1.5519e-01, -1.0258e-01,  3.3669e-01,  1.5076e-01,\n",
      "          3.7713e-01,  2.3614e-01,  1.2611e-01,  3.8887e-01, -2.7714e-01,\n",
      "          4.7804e-01, -2.3088e-01, -1.7281e-01, -1.8863e-02,  4.0840e-01,\n",
      "          1.3712e-01, -2.0993e-01,  1.1311e-01,  2.2078e-01,  1.5162e-01,\n",
      "         -7.4148e-02, -4.2448e-01, -2.2929e-01,  1.5066e-01, -3.1443e-01,\n",
      "          2.0998e-02,  2.5732e-01, -1.2737e-01, -1.8038e-01,  6.3251e-02,\n",
      "         -2.5188e-01, -4.7639e-01,  1.4728e-02, -4.8221e-02,  3.4589e-01,\n",
      "         -3.0654e-02, -1.9621e-02, -6.7335e-02, -2.8109e-02,  3.1179e-01,\n",
      "         -3.5993e-02,  2.2180e-01, -3.2787e-02, -1.0661e-01, -1.8473e-02,\n",
      "         -1.7413e-01,  7.7514e-02, -5.1171e+00, -4.4547e-02,  1.3403e-01,\n",
      "         -1.9503e-01, -5.4257e-01, -3.0316e-01, -3.4842e-01, -3.3726e-01,\n",
      "         -3.4020e-02, -1.4537e-01,  1.9274e-01, -1.0513e-01,  2.5094e-02,\n",
      "          5.8411e-02,  4.8391e-01,  3.1577e-01]])\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode with distil\n",
    "with torch.no_grad():\n",
    "    token_ids, attention_mask = tokenize(X_train[0])\n",
    "    model = DistilBertSequence(config)\n",
    "    x = token_ids.reshape(1,len(token_ids))\n",
    "    \n",
    "    out = model.forward(input_ids=x, attention_mask=attention_mask)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fdaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
